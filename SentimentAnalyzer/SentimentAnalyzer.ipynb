{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  URJITKUMAR PATEL - UP276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "import timeit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNow you have read all the files into list 'review' and it has been shuffled.\\nSave your shuffled result by pickle.\\n*Pickle is a useful module to serialize a python object structure. \\n*Check it out. https://wiki.python.org/moin/UsingPickle\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "'''\n",
    "Note: No obligation to use this code, though you may if you like.  Skeleton code is just a hint for people who are not familiar with text processing in python. \n",
    "It is not necessary to follow. \n",
    "'''\n",
    "\n",
    "\n",
    "def folder_list(path,label):\n",
    "    '''\n",
    "    PARAMETER PATH IS THE PATH OF YOUR LOCAL FOLDER\n",
    "    '''\n",
    "    filelist = os.listdir(path)\n",
    "    review = []\n",
    "    for infile in filelist:\n",
    "        file = os.path.join(path,infile)\n",
    "        r = read_data(file)\n",
    "        r.append(label)\n",
    "        review.append(r)\n",
    "    return review\n",
    "\n",
    "def read_data(file):\n",
    "    '''\n",
    "    Read each file into a list of strings. \n",
    "    Example:\n",
    "    [\"it's\", 'a', 'curious', 'thing', \"i've\", 'found', 'that', 'when', 'willis', 'is', 'not', 'called', 'on', \n",
    "    ...'to', 'carry', 'the', 'whole', 'movie', \"he's\", 'much', 'better', 'and', 'so', 'is', 'the', 'movie']\n",
    "    '''\n",
    "    f = open(file)\n",
    "    lines = f.read().split(' ')\n",
    "    symbols = '${}()[].,:;+-*/&|<>=~\" '\n",
    "    words = map(lambda Element: Element.translate(None, symbols).strip(), lines)\n",
    "    words = filter(None, words)\n",
    "    return words\n",
    "\n",
    "###############################################\n",
    "######## YOUR CODE STARTS FROM HERE. ##########\n",
    "###############################################\n",
    "\n",
    "def shuffle_data():\n",
    "    '''\n",
    "    pos_path is where you save positive review data.\n",
    "    neg_path is where you save negative review data.\n",
    "    '''\n",
    "    #pos_path = \"E://Data Science/ML/hw3-sentiment/data/neg\"\n",
    "    #neg_path = \"E://Data Science/ML/hw3-sentiment/data/pos\"\n",
    "    neg_path = \"/home/urjit/MachineLearning/data/neg\"\n",
    "    pos_path = \"/home/urjit/MachineLearning/data/pos\"\n",
    "    #neg_path = \n",
    "\n",
    "    pos_review = folder_list(pos_path,1)\n",
    "    neg_review = folder_list(neg_path,-1)\n",
    "\n",
    "    review = pos_review + neg_review\n",
    "    random.shuffle(review)\n",
    "    #print review[1][1]\n",
    "    #print review\n",
    "    return review\n",
    "\n",
    "'''\n",
    "Now you have read all the files into list 'review' and it has been shuffled.\n",
    "Save your shuffled result by pickle.\n",
    "*Pickle is a useful module to serialize a python object structure. \n",
    "*Check it out. https://wiki.python.org/moin/UsingPickle\n",
    "'''\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review = shuffle_data()\n",
    "#print review[2][-1]\n",
    "pickle.dump( review, open( \"/home/urjit/MachineLearning/data/review.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sparse Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_p = pickle.load( open( \"/home/urjit/MachineLearning/data/review.p\", \"rb\" ) )\n",
    "#print review_p[1][-1]\n",
    "#print len(review_p)\n",
    "y = list()\n",
    "review_counter = list()\n",
    "\n",
    "for i in range(len(review_p)):\n",
    "    y.append(review_p[i].pop(-1))\n",
    "\n",
    "for i in range(len(review_p)):\n",
    "    review_counter.append(Counter(review_p[i]))\n",
    "    \n",
    "#review_counter[1]\n",
    "#print type(review_counter)\n",
    "#print y\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( review_counter, y, test_size=0.25)\n",
    "#print X_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dotProduct(d1, d2):\n",
    "    \"\"\"\n",
    "    @param dict d1: a feature vector represented by a mapping from a feature (string) to a weight (float).\n",
    "    @param dict d2: same as d1\n",
    "    @return float: the dot product between d1 and d2\n",
    "    \"\"\"\n",
    "    if len(d1) < len(d2):\n",
    "        return dotProduct(d2, d1)\n",
    "    else:\n",
    "        return sum(d1.get(f, 0) * v for f, v in d2.items())\n",
    "\n",
    "def increment(d1, scale, d2):\n",
    "    \"\"\"\n",
    "    Implements d1 += scale * d2 for sparse vectors.\n",
    "    @param dict d1: the feature vector which is mutated.\n",
    "    @param float scale\n",
    "    @param dict d2: a feature vector.\n",
    "\n",
    "    NOTE: This function does not return anything, but rather\n",
    "    increments d1 in place. We do this because it is much faster to\n",
    "    change elements of d1 in place than to build a new dictionary and\n",
    "    return it.\n",
    "    \"\"\"\n",
    "    for f, v in d2.items():\n",
    "        d1[f] = d1.get(f, 0) + v * scale\n",
    "        \n",
    "def calculate_error(X, y, theta):\n",
    "    \"\"\"\n",
    "    Given a set of X, y, theta, compute the square loss for predicting y with X*theta\n",
    "    \n",
    "    Args:\n",
    "        X - the feature vector, 2D numpy array of size (num_instances, num_features)\n",
    "        y - the label vector, 1D numpy array of size (num_instances)\n",
    "        theta - the parameter vector, 1D array of size (num_features)\n",
    "    \n",
    "    Returns:\n",
    "        loss - the square loss, scalar\n",
    "    \"\"\"\n",
    "    loss = 0 #initialize the square_loss\n",
    "    m = len(theta)\n",
    "    #print m\n",
    "    n = len(X)\n",
    "    #print n\n",
    "    y_hat = list()\n",
    "    for i in range(0,n):\n",
    "        output = dotProduct(X[i],theta)\n",
    "        y_hat.append(output)\n",
    "        #print output\n",
    "   \n",
    "    y_hat = np.sign(y_hat)\n",
    "    acc = accuracy_score(y, y_hat)\n",
    "    print 'Accuracy :', acc\n",
    "    print 'Error :', 1-acc\n",
    "    return (1-acc)\n",
    "    #hypothesis = dotProduct(X,theta)\n",
    "    #loss = y_hat - y\n",
    "    #cost = float(np.sum(loss ** 2) / (2 * m))\n",
    "    #return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine via Pegasos ( all answers in sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.889333333333\n",
      "Error : 0.110666666667\n",
      "On Testing :\n",
      "Accuracy : 0.776\n",
      "Error : 0.224\n",
      "Average runtime for pegasos1 Algorithm method : 88.030327177\n",
      "\n",
      "[('see', 2.0527859237536643), ('you', 1.852839242868568), ('great', 1.772860570514525), ('jackie', 1.7595307917888572), ('best', 1.7328712343375057), ('fun', 1.6928818981604892), ('job', 1.6795521194348195), ('well', 1.6662223407091377), ('many', 1.6528925619834702), ('seen', 1.6129032258064437)]\n"
     ]
    }
   ],
   "source": [
    "def pegasosAlgorithmI(lamdbaValue, max_epochs):\n",
    "    #X = pickle.load( open( \"E://Data Science/ML/hw3-sentiment/data_new/Xtrain.p\", \"rb\" ) )\n",
    "    #y = pickle.load( open( \"E://Data Science/ML/hw3-sentiment/data_new/ytrain.p\", \"rb\" ) )\n",
    "    #print X[1]\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    numInstances = len(X)\n",
    "    avg_run_time = 0\n",
    "    total_run_time = 0\n",
    "    start_time = 0\n",
    "    stop_time = 0\n",
    "    epoch_total_runtime = list()\n",
    "    lambdaValue = lamdbaValue\n",
    "    #print y\n",
    "    #max_epochs = 5\n",
    "    #numInstances = len(X)\n",
    "    #print numInstances\n",
    "    #lambdaValue = 10**(-2)\n",
    "    w = dict()\n",
    "    t = 2\n",
    "    X = X_train\n",
    "    #X = pickle.load( open( \"Xtrain.p\", \"rb\" ) )\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print \"Running epoch #\",epoch\n",
    "        start_time = timeit.default_timer() \n",
    "        for j in range(numInstances):\n",
    "           \n",
    "            t = t + 1\n",
    "            eta_t = 1 / (t * lambdaValue)\n",
    "\n",
    "            cond = y[j] * dotProduct(w, X[j])\n",
    "            increment(w, -eta_t*lambdaValue, w)        # updates w in place\n",
    "                 \n",
    "            if cond < 1:\n",
    "                #print \"subgradient < 1\"\n",
    "                increment(w, (eta_t*y[j]), X[j])\n",
    "                #w_tplus1 = w            \n",
    "            #else:\n",
    "                #print \"subgradient > 1!\"\n",
    "                #w_tplus1 = w\n",
    "        stop_time = timeit.default_timer()\n",
    "        total_run_time = stop_time - start_time\n",
    "        epoch_total_runtime.append(total_run_time)\n",
    "    #print len(w)\n",
    "    #return w\n",
    "    theta = w\n",
    "    print \"On Training :\"\n",
    "    calculate_error(X_train, y_train, theta)\n",
    "    print \"On Testing :\"\n",
    "    calculate_error(X_test, y_test, theta)\n",
    "    plt.plot(range(max_epochs), epoch_total_runtime , label= \"Loss on testing data\")\n",
    "    #plt.xscale('log')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.ylabel('Time taken by the pegasos')\n",
    "    #plt.show()\n",
    "    plt.savefig(\"pegasos2.png\")\n",
    "    plt.clf()\n",
    "    avg_time = float(sum(epoch_total_runtime)/len(epoch_total_runtime))\n",
    "    print 'Average runtime for pegasos1 Algorithm method :',avg_time\n",
    "    print \n",
    "    sorted_w = sorted(theta.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    print sorted_w[0:10]\n",
    "    \n",
    "\n",
    "theta = pegasosAlgorithmI(10**(-2), 5)\n",
    "#print sum(theta.values())\n",
    "#print \"On Training :\"\n",
    "#compute_square_loss(X_train, y_train, theta)\n",
    "#print \"On Testing :\"\n",
    "#compute_square_loss(X_test, y_test, theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Lambda : 0.01\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.767333333333\n",
      "Error : 0.232666666667\n",
      "On Testing :\n",
      "Accuracy : 0.686\n",
      "Error : 0.314\n",
      "Average runtime for pegasos2 Algorithm method : 0.276184368134\n",
      "\n",
      "[('great', 2.9725406558245595), ('jackie', 2.3193814982678305), ('movies', 2.2793921620905166), ('seen', 1.9861370301250645), ('best', 1.8528392428688676), ('he', 1.77286057051424), ('well', 1.7195414556117612), ('you', 1.7195414556117612), ('quite', 1.6662223407092824), ('see', 1.6262330045319686)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb50cac4c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pegasosAlgorithmII(lamdbaValue, max_epochs):    \n",
    "    #X = pickle.load( open( \"Xtrain.p\", \"rb\" ) )\n",
    "    #y = pickle.load( open( \"ytrain.p\", \"rb\" ) )\n",
    "    print \n",
    "    print \"For Lambda :\",lamdbaValue\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    numInstances = len(X)\n",
    "    avg_run_time = 0\n",
    "    total_run_time = 0\n",
    "    start_time = 0\n",
    "    stop_time = 0\n",
    "    epoch_total_runtime = list()\n",
    "    lambdaValue = lamdbaValue\n",
    "  \n",
    "    s = 1\n",
    "    W = dict()    \n",
    "    t = 2       # Starting the range at 2 prevents W from being undefined\n",
    "    \n",
    "    for epoch in range(max_epochs):  \n",
    "        print \"Running epoch #\",epoch\n",
    "        start_time = timeit.default_timer() \n",
    "        for j in range(numInstances):        \n",
    "            t = t + 1\n",
    "            eta_t = 1 / (t * lambdaValue)\n",
    "\n",
    "            margin = y[j] * dotProduct(W, X[j])\n",
    "            s = (1 - (eta_t * lambdaValue)) * s\n",
    "\n",
    "            if s == 0:\n",
    "                s = 1\n",
    "                W = dict()\n",
    "\n",
    "            if margin < (1 / s):  # if misclassified               \n",
    "                increment(W, (1/s) * eta_t * y[j], X[j])        # updates W in place   \n",
    "\n",
    "            #else:                \n",
    "            #    for key in W:    \n",
    "            #        W[key] *=  s      \n",
    "        stop_time = timeit.default_timer()\n",
    "        total_run_time = stop_time - start_time\n",
    "        epoch_total_runtime.append(total_run_time)\n",
    "    increment(W, s-1, W)    # rescales W      \n",
    "    #return W\n",
    "\n",
    "    theta = W\n",
    "    print \"On Training :\"\n",
    "    train_loss = calculate_error(X_train, y_train, theta)\n",
    "    print \"On Testing :\"\n",
    "    test_loss = calculate_error(X_test, y_test, theta)\n",
    "    plt.plot(range(max_epochs), epoch_total_runtime , label= \"Loss on testing data\")\n",
    "    #plt.xscale('log')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.ylabel('Time taken by the pegasos')\n",
    "    #plt.show()\n",
    "    plt.savefig(\"pegasos2.png\")\n",
    "    plt.clf()\n",
    "    avg_time = float(sum(epoch_total_runtime)/len(epoch_total_runtime))\n",
    "    print 'Average runtime for pegasos2 Algorithm method :',avg_time\n",
    "    print \n",
    "    sorted_w = sorted(theta.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    print sorted_w[0:10]\n",
    "    return train_loss,test_loss,theta\n",
    "    \n",
    "\n",
    "train_loss,test_loss,theta = pegasosAlgorithmII(10**(-2), 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see above, I got same results using two versions of Pegasos Algorithm. \n",
    "\n",
    "On Training :\n",
    "Accuracy : 0.889333333333\n",
    "Error : 0.110666666667\n",
    "On Testing :\n",
    "Accuracy : 0.776\n",
    "Error : 0.224\n",
    "\n",
    "[('see', 2.0527859237536177), ('you', 1.8528392428688676), ('great', 1.77286057051424), ('jackie', 1.759530791789075), ('best', 1.7328712343378356), ('fun', 1.6928818981605218), ('job', 1.6795521194344474), ('well', 1.6662223407092824), ('many', 1.652892561983208), ('seen', 1.6129032258068037)]\n",
    "\n",
    "## But, second version of algorithm is way faster than first one. We can see the time difference.\n",
    "\n",
    "For first one : Average runtime for pegasos2 Algorithm method : 88.030327177\n",
    "    \n",
    "For second one : Average runtime for pegasos2 Algorithm method : 0.326152992249\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_prediction(X, y, theta):\n",
    "\n",
    "    loss = 0 #initialize the square_loss\n",
    "    m = len(theta)\n",
    "    #print m\n",
    "    n = len(X)\n",
    "    #print n\n",
    "    y_hat = list()\n",
    "    for i in range(0,n):\n",
    "        output = dotProduct(X[i],theta)\n",
    "        y_hat.append(output)\n",
    "        #print output\n",
    "   \n",
    "    y_hat = np.sign(y_hat)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_percent_error(w, X, y):\n",
    "    n = len(X)\n",
    "    n_error = 0\n",
    "    #for i in range(n):\n",
    "    #    X_i = X[i]\n",
    "    prediction = calculate_prediction(X, y, w)\n",
    "    #print prediction\n",
    "    for i in range(n):\n",
    "        if prediction[i]*y[i] < 0 :\n",
    "            n_error +=1\n",
    "    error = n_error/float(n)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error :  0.224\n"
     ]
    }
   ],
   "source": [
    "error = calculate_percent_error(theta,X_test, y_test)\n",
    "print \"error : \",error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Lambda : 1e-05\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.925333333333\n",
      "Error : 0.0746666666667\n",
      "On Testing :\n",
      "Accuracy : 0.812\n",
      "Error : 0.188\n",
      "Average runtime for pegasos2 Algorithm method : 1.07196602821\n",
      "\n",
      "[('great', 3132.4980005323887), ('jackie', 2479.3388429749757), ('movies', 2199.4134897356853), ('you', 1906.1583577711135), ('well', 1732.8712343377993), ('quite', 1706.2116768863052), ('seen', 1679.5521194348112), ('job', 1572.9138896297663), ('she', 1572.9138896297663), ('most', 1559.5841109035537)]\n",
      "\n",
      "For Lambda : 0.0001\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.925333333333\n",
      "Error : 0.0746666666667\n",
      "On Testing :\n",
      "Accuracy : 0.812\n",
      "Error : 0.188\n",
      "Average runtime for pegasos2 Algorithm method : 1.01531224251\n",
      "\n",
      "[('great', 313.24980005342513), ('jackie', 247.93388429749757), ('movies', 219.94134897366166), ('you', 190.61583577713463), ('well', 173.28712343377993), ('quite', 170.62116768863052), ('seen', 167.95521194348112), ('job', 157.29138896299992), ('she', 157.29138896299992), ('most', 155.95841109042522)]\n",
      "\n",
      "For Lambda : 0.001\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.713333333333\n",
      "Error : 0.286666666667\n",
      "On Testing :\n",
      "Accuracy : 0.644\n",
      "Error : 0.356\n",
      "Average runtime for pegasos2 Algorithm method : 1.05127620697\n",
      "\n",
      "[('great', 30.925086643561372), ('jackie', 23.993601706213667), ('you', 17.861903492404963), ('movies', 17.728605705138762), ('see', 17.595307917887112), ('seen', 16.528925619837537), ('job', 16.262330045319686), ('most', 15.32924553452176), ('chan', 14.92935217275226), ('also', 14.662756598241685)]\n",
      "\n",
      "For Lambda : 0.01\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.767333333333\n",
      "Error : 0.232666666667\n",
      "On Testing :\n",
      "Accuracy : 0.686\n",
      "Error : 0.314\n",
      "Average runtime for pegasos2 Algorithm method : 1.04088282585\n",
      "\n",
      "[('great', 2.9725406558245595), ('jackie', 2.3193814982678305), ('movies', 2.2793921620905166), ('seen', 1.9861370301250645), ('best', 1.8528392428688676), ('he', 1.77286057051424), ('well', 1.7195414556117612), ('you', 1.7195414556117612), ('quite', 1.6662223407092824), ('see', 1.6262330045319686)]\n",
      "\n",
      "For Lambda : 0.1\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.824\n",
      "Error : 0.176\n",
      "On Testing :\n",
      "Accuracy : 0.704\n",
      "Error : 0.296\n",
      "Average runtime for pegasos2 Algorithm method : 1.06890654564\n",
      "\n",
      "[('great', 0.37856571580914533), ('jackie', 0.2812583311117578), ('movies', 0.23860303918957015), ('also', 0.23727006131696271), ('you', 0.23193814982676031), ('well', 0.20927752599311589), ('quite', 0.2039456145027998), ('chan', 0.19328179152228131), ('most', 0.19061583577718011), ('seen', 0.18794988003196522)]\n",
      "\n",
      "For Lambda : 1\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "On Testing :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "Average runtime for pegasos2 Algorithm method : 1.46727676392\n",
      "\n",
      "[(\"cake'\", 0), ('sonja', 0), ('astrosbraves', 0), ('woods', 0), ('spiders', 0), ('gavan', 0), ('hanging', 0), ('woody', 0), ('comically', 0), ('localized', 0)]\n",
      "\n",
      "For Lambda : 10\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "On Testing :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "Average runtime for pegasos2 Algorithm method : 1.44273414612\n",
      "\n",
      "[(\"cake'\", 0), ('sonja', 0), ('astrosbraves', 0), ('woods', 0), ('spiders', 0), ('gavan', 0), ('hanging', 0), ('woody', 0), ('comically', 0), ('localized', 0)]\n",
      "\n",
      "For Lambda : 100\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "On Testing :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "Average runtime for pegasos2 Algorithm method : 1.55167922974\n",
      "\n",
      "[(\"cake'\", 0), ('sonja', 0), ('astrosbraves', 0), ('woods', 0), ('spiders', 0), ('gavan', 0), ('hanging', 0), ('woody', 0), ('comically', 0), ('localized', 0)]\n",
      "\n",
      "For Lambda : 1000\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "On Testing :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "Average runtime for pegasos2 Algorithm method : 1.51378540993\n",
      "\n",
      "[(\"cake'\", 0), ('sonja', 0), ('astrosbraves', 0), ('woods', 0), ('spiders', 0), ('gavan', 0), ('hanging', 0), ('woody', 0), ('comically', 0), ('localized', 0)]\n",
      "\n",
      "For Lambda : 10000\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "On Testing :\n",
      "Accuracy : 0.0\n",
      "Error : 1.0\n",
      "Average runtime for pegasos2 Algorithm method : 1.52129888535\n",
      "\n",
      "[(\"cake'\", 0), ('sonja', 0), ('astrosbraves', 0), ('woods', 0), ('spiders', 0), ('gavan', 0), ('hanging', 0), ('woody', 0), ('comically', 0), ('localized', 0)]\n",
      "[0.18799999999999994, 0.18799999999999994, 0.35599999999999998, 0.31399999999999995, 0.29600000000000004, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEnCAYAAACzCdQdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb50cac4c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4dd25e7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "LambdaValues = [10**(i) for i in np.arange(-5,5)]\n",
    "max_epochs = 5\n",
    "train_loss_list = list()\n",
    "test_loss_list = list()\n",
    "trainLoss = 0\n",
    "testLoss = 0\n",
    "\n",
    "for Lambda in LambdaValues:\n",
    "    trainLoss,testLoss,theta = pegasosAlgorithmII(Lambda,max_epochs)\n",
    "    train_loss_list.append(trainLoss)\n",
    "    test_loss_list.append(testLoss)\n",
    "    \n",
    "print test_loss_list\n",
    "plt.plot(LambdaValues, train_loss_list , label= \"Error on training data\")\n",
    "plt.plot(LambdaValues, test_loss_list , label= \"Error on testing data\")\n",
    "plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('lambda values (log scale)')\n",
    "plt.ylabel('Error value')\n",
    "plt.suptitle('Error as a function of lambda')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"RegularizationPath.png\")\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So As we can see above in plot I got the minimum testing error approximately at lambda = 10**(-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def findMisclassified(w, X, y):\n",
    "    n = len(X)\n",
    "    misclassified = []\n",
    "    predictionlist = calculate_prediction(X, y, w)\n",
    "    for i in range(n):\n",
    "        X_i = X[i]\n",
    "        prediction = predictionlist[1]\n",
    "        misclassified.append([])\n",
    "        misclassified[i].append([\"prediction =\",dotProduct(w, X_i),\"true label =\",y[i]])\n",
    "        misclassified[i].append([\"word\",\"wixi\",\"wi\",\"xi\"])\n",
    "        if prediction*y[i] < 0 :\n",
    "            a = {}\n",
    "            for f, v in X_i.items():\n",
    "                a[f] = w.get(f, 0) * v \n",
    "                word = f\n",
    "                wixi = w.get(f, 0) * v\n",
    "                wi = w.get(f, 0)\n",
    "                xi = v\n",
    "                misclassified[i].append([word,wixi,wi,xi])\n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['prediction =', -12.583311117030107, 'true label =', -1],\n",
       " ['word', 'wixi', 'wi', 'xi'],\n",
       " ['more', -0.0799786723540592, -0.0799786723540592, 1],\n",
       " ['summer', 1.3996267661955244, 0.46654225539850813, 3],\n",
       " ['all', -1.4396161023723835, -0.7198080511861917, 2],\n",
       " ['being', 0.3465742468674762, 0.3465742468674762, 1],\n",
       " ['over', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['queen', 0.10663822980541227, 0.10663822980541227, 1],\n",
       " ['actress', 0.27992535323915035, 0.27992535323915035, 1],\n",
       " ['keanu', -0.1732871234337381, -0.1732871234337381, 1],\n",
       " ['four', 0.37323380431894293, 0.37323380431894293, 1],\n",
       " ['windy', 0, 0, 1],\n",
       " ['geller', -0.0399893361770296, -0.0399893361770296, 1],\n",
       " [\"90's\", 0.05331911490270613, 0.05331911490270613, 1],\n",
       " ['illogical', -0.18661690215947146, -0.18661690215947146, 1],\n",
       " [\"five's\", 0, 0, 1],\n",
       " ['love', 0.7864569448147449, 0.7864569448147449, 1],\n",
       " ['bunch', -0.6931484937349524, -0.6931484937349524, 1],\n",
       " ['cut', 0.026659557451353066, 0.013329778725676533, 2],\n",
       " ['based', 0.18661690215947146, 0.18661690215947146, 1],\n",
       " ['elm', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['reeves', -0.3865635830445626, -0.3865635830445626, 1],\n",
       " ['ruin', -0.05331911490270613, -0.05331911490270613, 1],\n",
       " ['him', -0.27992535323915035, -0.27992535323915035, 1],\n",
       " ['better', -1.066382298053668, -1.066382298053668, 1],\n",
       " ['to', -6.118368435083994, -0.6798187150093327, 9],\n",
       " ['going', 0.706478272460572, 0.706478272460572, 1],\n",
       " ['main', -3.2524660090639372, -0.8131165022659843, 4],\n",
       " ['carolina', -0.0399893361770296, -0.0399893361770296, 1],\n",
       " ['actresses', -0.05331911490270613, -0.05331911490270613, 1],\n",
       " ['town', 0.826446280991604, 0.413223140495802, 2],\n",
       " ['them', 0.14662756598238502, 0.14662756598238502, 1],\n",
       " ['his', -0.8531058384432981, -0.42655291922164906, 2],\n",
       " ['worse', -0.4798720341243552, -0.4798720341243552, 1],\n",
       " ['jerk', 0.0799786723540592, 0.0799786723540592, 1],\n",
       " ['disappointingly', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['smarter', -0.1199680085310888, -0.1199680085310888, 1],\n",
       " ['horror', 0.2532657957877973, 0.2532657957877973, 1],\n",
       " ['killer', 0.18661690215947146, 0.18661690215947146, 1],\n",
       " ['possible', -0.14662756598238502, -0.14662756598238502, 1],\n",
       " ['football', -0.46654225539850813, -0.46654225539850813, 1],\n",
       " ['worst', -2.0527859237536177, -2.0527859237536177, 1],\n",
       " ['know', 0.2399360170621776, 0.0799786723540592, 3],\n",
       " ['they', 0.7597973873633919, 0.2532657957877973, 3],\n",
       " ['indulge', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['not', 0.5065315915755946, 0.2532657957877973, 2],\n",
       " ['world', 1.452945881098458, 1.452945881098458, 1],\n",
       " ['now', 0.35990402559309587, 0.35990402559309587, 1],\n",
       " ['discuss', 0.1199680085310888, 0.1199680085310888, 1],\n",
       " ['dreams', -0.19994668088509115, -0.19994668088509115, 1],\n",
       " ['matched', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['twists', 0.22660623833644422, 0.22660623833644422, 1],\n",
       " ['name', -0.42655291922164906, -0.42655291922164906, 1],\n",
       " ['success', 0.06664889362835424, 0.06664889362835424, 1],\n",
       " ['did', -1.8794988003205617, -0.6264996001068539, 3],\n",
       " ['james', -0.0399893361770296, -0.0399893361770296, 1],\n",
       " ['who', 0.9330845107970163, 0.9330845107970163, 1],\n",
       " ['having', -0.8397760597172237, -0.8397760597172237, 1],\n",
       " ['bright', -0.2399360170621776, -0.2399360170621776, 1],\n",
       " ['ryan', 0.14662756598238502, 0.14662756598238502, 1],\n",
       " ['bad', -26.392961876830668, -4.398826979471778, 6],\n",
       " ['fisherman', -0.10663822980541227, -0.10663822980541227, 1],\n",
       " ['guiding', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['rock', -0.1599573447081184, -0.1599573447081184, 1],\n",
       " ['small', 0.35990402559309587, 0.35990402559309587, 1],\n",
       " ['become', 0.8397760597172237, 0.8397760597172237, 1],\n",
       " ['guy', 0.06664889362838267, 0.06664889362838267, 1],\n",
       " ['works', 0.5731804852039204, 0.5731804852039204, 1],\n",
       " ['mean', -0.30658491069038973, -0.30658491069038973, 1],\n",
       " ['because', 0.14662756598238502, 0.14662756598238502, 1],\n",
       " ['climactic', 0.29325513196477004, 0.14662756598238502, 2],\n",
       " ['parade', -0.09330845107973573, -0.09330845107973573, 1],\n",
       " ['dump', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['count', -0.0799786723540592, -0.0799786723540592, 1],\n",
       " ['some', -1.9194881364974208, -0.21327645961082453, 9],\n",
       " ['mangled', -7.577101954253548e-18, -7.577101954253548e-18, 1],\n",
       " ['jennifer', -0.14662756598238502, -0.14662756598238502, 1],\n",
       " ['past', -0.3332444681418565, -0.3332444681418565, 1],\n",
       " ['see', 4.105571847507235, 2.0527859237536177, 2],\n",
       " ['street', 0.1199680085310888, 0.1199680085310888, 1],\n",
       " ['college', -0.7731271660891252, -0.3865635830445626, 2],\n",
       " ['result', -0.1732871234337381, -0.1732871234337381, 1],\n",
       " ['year', 0.27992535323915035, 0.27992535323915035, 1],\n",
       " ['unattractive', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['run', 0.14662756598238502, 0.14662756598238502, 1],\n",
       " ['scribe', -2.121588547191372e-16, -2.121588547191372e-16, 1],\n",
       " ['thinks', -0.1599573447081184, -0.1599573447081184, 1],\n",
       " ['best', 1.7328712343378356, 1.7328712343378356, 1],\n",
       " ['out', -0.6264996001068539, -0.6264996001068539, 1],\n",
       " ['even', -1.3063183151161866, -1.3063183151161866, 1],\n",
       " ['living', -0.6398293788324736, -0.6398293788324736, 1],\n",
       " ['what', 0.9597440682487104, 0.2399360170621776, 4],\n",
       " ['followed', -0.1199680085310888, -0.1199680085310888, 1],\n",
       " ['mood', 0.29325513196477004, 0.29325513196477004, 1],\n",
       " ['for', 1.3996267661955244, 0.46654225539850813, 3],\n",
       " ['decision', 0.013329778725676533, 0.013329778725676533, 1],\n",
       " ['movie', -3.1191682218072856, -1.0397227406024285, 3],\n",
       " ['nightmare', 0.1599573447081184, 0.1599573447081184, 1],\n",
       " ['shivers', 0, 0, 1],\n",
       " ['acting', -1.3063183151161866, -0.6531591575580933, 2],\n",
       " ['does', 1.0397227406024285, 1.0397227406024285, 1],\n",
       " ['taunting', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['then', -1.226339642761559, -1.226339642761559, 1],\n",
       " ['wittily', 0, 0, 1],\n",
       " ['prinze', -0.2532657957877973, -0.2532657957877973, 1],\n",
       " ['urban', -0.29325513196477004, -0.29325513196477004, 1],\n",
       " ['fun', 1.6928818981605218, 1.6928818981605218, 1],\n",
       " ['we', 0.10663822980541227, 0.05331911490270613, 2],\n",
       " ['after', 0.18661690215947146, 0.18661690215947146, 1],\n",
       " ['hero', -0.4798720341243552, -0.4798720341243552, 1],\n",
       " ['plot', -5.011996800854831, -2.5059984004274156, 2],\n",
       " ['respectively', 0.29325513196477004, 0.29325513196477004, 1],\n",
       " ['team', -0.6398293788324736, -0.6398293788324736, 1],\n",
       " ['night', -0.266595574513417, -0.266595574513417, 1],\n",
       " ['costumes', -0.1332977872567085, -0.1332977872567085, 1],\n",
       " ['jr', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['killing', -0.3465742468674762, -0.3465742468674762, 1],\n",
       " ['crossing', -0.013329778725676533, -0.013329778725676533, 1],\n",
       " ['protagonist', -0.1732871234337381, -0.1732871234337381, 1],\n",
       " ['chances', 0.0799786723540592, 0.0799786723540592, 1],\n",
       " ['concluding', 1.3259928419946075e-17, 1.3259928419946075e-17, 1],\n",
       " ['crowned', 0, 0, 1],\n",
       " ['along', 0.42655291922164906, 0.42655291922164906, 1],\n",
       " ['come', 0.29325513196477004, 0.29325513196477004, 1],\n",
       " ['by', -1.3862969874699047, -0.1732871234337381, 8],\n",
       " ['on', -4.198880298586118, -0.8397760597172237, 5],\n",
       " ['about', -0.9064249533457769, -0.9064249533457769, 1],\n",
       " ['last', 0.9597440682487104, 0.3199146894162368, 3],\n",
       " ['thirty', -0.37323380431894293, -0.37323380431894293, 1],\n",
       " ['getting', -0.4798720341243552, -0.2399360170621776, 2],\n",
       " ['of', 5.398560383896438, 0.35990402559309587, 15],\n",
       " ['could', -0.9997334044255695, -0.9997334044255695, 1],\n",
       " ['so', -1.999466808851139, -0.9997334044255695, 2],\n",
       " ['times', 0.37323380431894293, 0.37323380431894293, 1],\n",
       " ['angsthorror', 0, 0, 1],\n",
       " ['barry', -0.026659557451353066, -0.026659557451353066, 1],\n",
       " ['eyecatching', -6.440536661116305e-17, -6.440536661116305e-17, 1],\n",
       " ['adapted', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['think', 0.5065315915755946, 0.5065315915755946, 1],\n",
       " ['road', -0.5198613703012143, -0.5198613703012143, 1],\n",
       " ['otherwise', 0.1732871234337381, 0.1732871234337381, 1],\n",
       " ['appropriately', 0.18661690215947146, 0.18661690215947146, 1],\n",
       " ['woodenly', 0, 0, 3],\n",
       " ['smarts', 0, 0, 1],\n",
       " ['starring', -0.3332444681418565, -0.3332444681418565, 1],\n",
       " ['family', 0.6131698213807795, 0.6131698213807795, 1],\n",
       " ['drunk', -0.18661690215947146, -0.18661690215947146, 1],\n",
       " ['julie', -0.42655291922164906, -0.42655291922164906, 1],\n",
       " ['good', 0.546520927752681, 0.546520927752681, 1],\n",
       " ['scene', 0.1332977872567085, 0.1332977872567085, 1],\n",
       " ['bronson', -0.1332977872567085, -0.1332977872567085, 1],\n",
       " ['one', 0.5065315915755946, 0.2532657957877973, 2],\n",
       " ['down', -0.14662756598238502, -0.14662756598238502, 1],\n",
       " ['improbable', -0.013329778725676533, -0.013329778725676533, 1],\n",
       " ['appropriate', -0.29325513196477004, -0.29325513196477004, 1],\n",
       " ['set', 0.2532657957877973, 0.2532657957877973, 1],\n",
       " ['female', -1.3596374300186653, -0.45321247667288844, 3],\n",
       " ['heche', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['your', 1.2796587576649472, 1.2796587576649472, 1],\n",
       " ['sarah', -0.1332977872567085, -0.1332977872567085, 1],\n",
       " ['startling', 0.013329778725676533, 0.013329778725676533, 1],\n",
       " ['trendily', 0, 0, 1],\n",
       " ['from', 1.3862969874699047, 0.6931484937349524, 2],\n",
       " ['her', -0.6931484937349524, -0.3465742468674762, 2],\n",
       " ['failed', -0.1199680085310888, -0.1199680085310888, 1],\n",
       " [\"it's\", 1.4396161023723835, 0.7198080511861917, 2],\n",
       " ['top', 0.1332977872567085, 0.1332977872567085, 1],\n",
       " ['there', -0.4798720341243552, -0.4798720341243552, 1],\n",
       " ['plagued', 0.1199680085310888, 0.1199680085310888, 1],\n",
       " ['been', -1.8661690215940325, -0.9330845107970163, 2],\n",
       " ['legend', -0.35990402559309587, -0.35990402559309587, 1],\n",
       " ['their', 0.026659557451338856, 0.013329778725669428, 2],\n",
       " ['2', 0.09330845107973573, 0.09330845107973573, 1],\n",
       " ['music', 0.4932018128499749, 0.4932018128499749, 1],\n",
       " ['combined', -3.030840781701419e-17, -3.030840781701419e-17, 1],\n",
       " ['way', 1.0530525193280482, 1.0530525193280482, 1],\n",
       " ['mysterious', -0.10663822980541227, -0.10663822980541227, 1],\n",
       " [\"scream's\", 0.013329778725676533, 0.013329778725676533, 1],\n",
       " ['was', 0.05331911490270613, 0.05331911490270613, 1],\n",
       " ['tell', -0.3865635830445626, -0.3865635830445626, 1],\n",
       " ['store', -0.19994668088509115, -0.19994668088509115, 1],\n",
       " ['hewitt', -0.1199680085310888, -0.1199680085310888, 1],\n",
       " ['teen', -0.3998933617701823, -0.3998933617701823, 1],\n",
       " ['slasher', -0.27992535323915035, -0.27992535323915035, 1],\n",
       " ['williamson', -0.1732871234337381, -0.1732871234337381, 1],\n",
       " ['north', 0.2399360170621776, 0.2399360170621776, 1],\n",
       " ['complete', -0.22660623833644422, -0.22660623833644422, 1],\n",
       " ['mostly', 0.1599573447081184, 0.0799786723540592, 2],\n",
       " ['that', -0.666488936283713, -0.3332444681418565, 2],\n",
       " ['predictably', -0.09330845107973573, -0.09330845107973573, 1],\n",
       " ['believe', 0.37323380431894293, 0.37323380431894293, 1],\n",
       " ['back', 1.3596374300186653, 1.3596374300186653, 1],\n",
       " ['lives', 0.1599573447081184, 0.1599573447081184, 1],\n",
       " ['helen', -0.05331911490270613, -0.05331911490270613, 1],\n",
       " ['july', 0.1599573447081184, 0.1599573447081184, 1],\n",
       " ['sex', -0.22660623833644422, -0.22660623833644422, 1],\n",
       " ['with', 2.399360170620639, 0.5998400426551598, 4],\n",
       " ['than', 0.37323380431894293, 0.18661690215947146, 2],\n",
       " ['begins', -0.37323380431894293, -0.18661690215947146, 2],\n",
       " ['has', 1.5595841109036428, 0.5198613703012143, 3],\n",
       " ['look', -0.533191149026834, -0.533191149026834, 1],\n",
       " ['this', -1.759530791789075, -0.8797653958945375, 2],\n",
       " ['say', 0.6398293788324736, 0.6398293788324736, 1],\n",
       " ['while', 0.4798720341243552, 0.4798720341243552, 1],\n",
       " ['future', 0.18661690215947146, 0.18661690215947146, 1],\n",
       " ['guilt', 0.1199680085310888, 0.1199680085310888, 1],\n",
       " ['how', 0.45321247667288844, 0.45321247667288844, 1],\n",
       " ['cox', -0.09330845107973573, -0.09330845107973573, 1],\n",
       " ['angsty', -0.1599573447081184, -0.0799786723540592, 2],\n",
       " ['male', -0.1599573447081184, -0.0399893361770296, 4],\n",
       " ['flic', 0, 0, 1],\n",
       " ['imitation', -0.013329778725676533, -0.013329778725676533, 1],\n",
       " ['and', 15.355905091979366, 0.9597440682487104, 16],\n",
       " ['sort', -0.05331911490270613, -0.05331911490270613, 1],\n",
       " ['forfeited', 0, 0, 1],\n",
       " ['blond', -0.6398293788324736, -0.1599573447081184, 4],\n",
       " ['played', -1.0797120767792876, -0.35990402559309587, 3],\n",
       " ['almost', 0.3998933617701823, 0.3998933617701823, 1],\n",
       " ['is', 4.398826979473597, 0.7331378299122662, 6],\n",
       " ['modern', 0.10663822980541227, 0.10663822980541227, 1],\n",
       " ['mind', 0.666488936283713, 0.666488936283713, 1],\n",
       " ['it', -0.21327645961082453, -0.05331911490270613, 4],\n",
       " ['an', -2.119434817381716, -0.706478272460572, 3],\n",
       " ['as', 0.5331911490270613, 0.13329778725676533, 4],\n",
       " ['murder', 0.1732871234337381, 0.1732871234337381, 1],\n",
       " ['croaker', 0, 0, 1],\n",
       " ['at', -5.798453745669576, -1.1596907491339152, 5],\n",
       " ['have', -4.425486536922108, -2.212743268461054, 2],\n",
       " ['in', 3.1991468941614585, 0.3998933617701823, 8],\n",
       " ['females', 1.1365652931378744e-17, 1.1365652931378744e-17, 1],\n",
       " ['face', -0.06664889362838267, -0.06664889362838267, 1],\n",
       " ['any', -1.9328179152225857, -1.9328179152225857, 1],\n",
       " ['kevin', -0.706478272460572, -0.706478272460572, 1],\n",
       " ['ray', -0.3332444681418565, -0.3332444681418565, 1],\n",
       " ['gone', -0.4932018128499749, -0.4932018128499749, 1],\n",
       " ['comes', -0.3465742468674762, -0.3465742468674762, 1],\n",
       " ['annoying', -1.0130631831511892, -1.0130631831511892, 1],\n",
       " ['end', 0.2532657957877973, 0.2532657957877973, 1],\n",
       " ['phillipe', -0.0399893361770296, -0.0399893361770296, 1],\n",
       " ['make', -0.21327645961082453, -0.21327645961082453, 1],\n",
       " ['sitting', 0.19994668088509115, 0.19994668088509115, 1],\n",
       " ['same', 1.0797120767797423, 1.0797120767797423, 1],\n",
       " ['note', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['cinematography', -0.026659557451353066, -0.026659557451353066, 1],\n",
       " ['book', -0.266595574513417, -0.266595574513417, 1],\n",
       " ['actors', -1.0130631831511892, -0.5065315915755946, 2],\n",
       " ['party', 0.18661690215947146, 0.09330845107973573, 2],\n",
       " ['you', 9.264196214344338, 1.8528392428688676, 5],\n",
       " ['if', -1.1463609704078408, -1.1463609704078408, 1],\n",
       " ['beach', 0.05331911490270613, 0.05331911490270613, 1],\n",
       " ['quarterback', -0.026659557451353066, -0.026659557451353066, 1],\n",
       " ['relief', -0.18661690215947146, -0.18661690215947146, 1],\n",
       " ['irrational', 0, 0, 1],\n",
       " ['though', 1.9461476939486602, 0.9730738469743301, 2],\n",
       " ['our', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['protagonists', 0.2799253532392072, 0.09330845107973573, 3],\n",
       " ['freddie', -0.4798720341243552, -0.4798720341243552, 1],\n",
       " ['4th', 0.0399893361770296, 0.0399893361770296, 1],\n",
       " ['characters', -0.43988269794726875, -0.43988269794726875, 1],\n",
       " ['haunt', 0.013329778725676533, 0.013329778725676533, 1],\n",
       " ['pair', 0.533191149026834, 0.266595574513417, 2],\n",
       " ['meaningful', -0.09330845107973573, -0.09330845107973573, 1],\n",
       " ['anne', -0.026659557451353066, -0.026659557451353066, 1],\n",
       " ['cliff', -0.18661690215947146, -0.09330845107973573, 2],\n",
       " ['a', -1.6129032258062352, -0.14662756598238502, 11],\n",
       " ['michelle', 0.18661690215947146, 0.18661690215947146, 1],\n",
       " ['land', 0.1332977872567085, 0.1332977872567085, 1],\n",
       " ['off', -1.066382298053668, -0.533191149026834, 2],\n",
       " ['i', 1.5329245534519487, 0.30658491069038973, 5],\n",
       " ['light', 0.5598507064783007, 0.5598507064783007, 1],\n",
       " ['spout', 0, 0, 1],\n",
       " ['later', -0.026659557451353066, -0.026659557451353066, 1],\n",
       " ['lines', -1.5995734470807292, -0.7997867235403646, 2],\n",
       " ['ocean', 0.026659557451353066, 0.013329778725676533, 2],\n",
       " ['campy', -0.05331911490270613, -0.05331911490270613, 1],\n",
       " ['cheer', -5.114543819120435e-17, -5.114543819120435e-17, 1],\n",
       " ['without', 1.9194881364974208, 0.9597440682487104, 2],\n",
       " ['brunette', -0.37323380431894293, -0.09330845107973573, 4],\n",
       " [\"can't\", -1.2529992002137078, -1.2529992002137078, 1],\n",
       " ['pictures', 0.0799786723540592, 0.0799786723540592, 1],\n",
       " ['pleasure', 0.19994668088509115, 0.19994668088509115, 1],\n",
       " ['the', 13.596374300186199, 0.3998933617701823, 34],\n",
       " ['foreshadowing', 0.026659557451353066, 0.026659557451353066, 1],\n",
       " ['scream', 0.39989336177012547, 0.1332977872567085, 3],\n",
       " ['typical', 0.0399893361770296, 0.0399893361770296, 1]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified = findMisclassified(theta, X_test, y_test)\n",
    "misclassified[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So If we observe, our algorithm is assigning higher weights to the common words like \"a,an,the,for\" which occurs frequently. As an example,\n",
    "\n",
    "['the', 13.596374300186199, 0.3998933617701823, 34]\n",
    "\n",
    "for word 'the' = wixi value is \"13.60\" which is very high. \n",
    "\n",
    "## This words can make difference in our prediction. So we should remove these words also known as \"STOP WORDS\". Or we can use \"TF:IDF\" which will asign the weights according to count of word in document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = [\"the\",\"a\",\"and\",\"to\",\"of\",\"with\",\"in\",\"is\",\"as\",\"for\"]\n",
    "\n",
    "#{'the': 31, 'a': 21, 'to': 20, 'and': 12, 'his': 11, 'of': 11, 'with': 11, 'in': 10,\n",
    "# 'her': 8, 'is': 7, 'as': 7, 'but': 6, 'that': 5, 'on': 5, 'or': 5, 'an': 5, 'from': 4,\n",
    "# 'not': 4, 'sam': 4, 'have': 4, \"it's\": 4, 'it': 4, 'for': 4, 'happy': 4, 'again': 4, \n",
    "# 'accidents': 4, 'this': 3, 'over': 3, 'without':\n",
    "for word in stop_words:\n",
    "    for i in range(len(X_train)):\n",
    "        if X_train[i][word]>0:\n",
    "            X_train[i][word]=0\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        if X_test[i][word]>0:\n",
    "            X_test[i][word]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Lambda : 0.01\n",
      "Running epoch # 0\n",
      "Running epoch # 1\n",
      "Running epoch # 2\n",
      "Running epoch # 3\n",
      "Running epoch # 4\n",
      "On Training :\n",
      "Accuracy : 0.942666666667\n",
      "Error : 0.0573333333333\n",
      "On Testing :\n",
      "Accuracy : 0.802\n",
      "Error : 0.198\n",
      "Average runtime for pegasos2 Algorithm method : 0.238144397736\n",
      "\n",
      "[('fun', 1.0263929618768088), ('jackie', 0.8797653958945375), ('many', 0.8664356171689178), ('best', 0.826446280991604), ('sometimes', 0.7731271660891252), ('evil', 0.7464676086378859), ('he', 0.7198080511861917), ('hilarious', 0.666488936283713), ('perfectly', 0.666488936283713), ('well', 0.666488936283713)]\n"
     ]
    }
   ],
   "source": [
    "def pegasosAlgorithmII(lamdbaValue, max_epochs):    \n",
    "    #X = pickle.load( open( \"Xtrain.p\", \"rb\" ) )\n",
    "    #y = pickle.load( open( \"ytrain.p\", \"rb\" ) )\n",
    "    print \n",
    "    print \"For Lambda :\",lamdbaValue\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    numInstances = len(X)\n",
    "    avg_run_time = 0\n",
    "    total_run_time = 0\n",
    "    start_time = 0\n",
    "    stop_time = 0\n",
    "    epoch_total_runtime = list()\n",
    "    lambdaValue = lamdbaValue\n",
    "  \n",
    "    s = 1\n",
    "    W = dict()    \n",
    "    t = 2       # Starting the range at 2 prevents W from being undefined\n",
    "    \n",
    "    for epoch in range(max_epochs):  \n",
    "        print \"Running epoch #\",epoch\n",
    "        start_time = timeit.default_timer() \n",
    "        for j in range(numInstances):        \n",
    "            t = t + 1\n",
    "            eta_t = 1 / (t * lambdaValue)\n",
    "\n",
    "            margin = y[j] * dotProduct(W, X[j])\n",
    "            s = (1 - (eta_t * lambdaValue)) * s\n",
    "\n",
    "            if s == 0:\n",
    "                s = 1\n",
    "                W = dict()\n",
    "\n",
    "            if margin < (1 / s):  # if misclassified               \n",
    "                increment(W, (1/s) * eta_t * y[j], X[j])        # updates W in place   \n",
    "\n",
    "            #else:                \n",
    "            #    for key in W:    \n",
    "            #        W[key] *=  s      \n",
    "        stop_time = timeit.default_timer()\n",
    "        total_run_time = stop_time - start_time\n",
    "        epoch_total_runtime.append(total_run_time)\n",
    "    increment(W, s-1, W)    # rescales W      \n",
    "    #return W\n",
    "\n",
    "    theta = W\n",
    "    print \"On Training :\"\n",
    "    train_loss = calculate_error(X_train, y_train, theta)\n",
    "    print \"On Testing :\"\n",
    "    test_loss = calculate_error(X_test, y_test, theta)\n",
    "    plt.plot(range(max_epochs), epoch_total_runtime , label= \"Loss on testing data\")\n",
    "    #plt.xscale('log')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.ylabel('Time taken by the pegasos')\n",
    "    #plt.show()\n",
    "    plt.savefig(\"pegasos2.png\")\n",
    "    plt.clf()\n",
    "    avg_time = float(sum(epoch_total_runtime)/len(epoch_total_runtime))\n",
    "    print 'Average runtime for pegasos2 Algorithm method :',avg_time\n",
    "    print \n",
    "    sorted_w = sorted(theta.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    print sorted_w[0:10]\n",
    "    return train_loss,test_loss,theta\n",
    "    \n",
    "\n",
    "train_loss,test_loss,theta = pegasosAlgorithmII(10**(-2), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error :  0.198\n"
     ]
    }
   ],
   "source": [
    "error = calculate_percent_error(theta,X_test, y_test)\n",
    "print \"error : \",error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So I removed the stopwords [\"the\",\"a\",\"and\",\"to\",\"of\",\"with\",\"in\",\"is\",\"as\",\"for\"] and I improved error from  0.224 to 0.198. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
